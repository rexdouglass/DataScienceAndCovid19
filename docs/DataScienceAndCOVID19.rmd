---
title: "Data Science and COVID-19: 10 Current and Future Trends"
author:
  - name: Rex Douglass
    email: rexdouglass@gmail.com
    affiliation: University of California, San Diego
  - name: Thomas Leo Scherer
    email: tlscherer@ucsd.edu
    affiliation: University of California, San Diego
address:
  - code: University of California San Diego
    address: University of California, San Diego, La Jolla,CA, 92093
abstract: Abstract here

author_summary: |
  Lorem ipsum dolor sit amet, consectetur adipiscing elit. Curabitur eget porta erat. Morbi consectetur est vel gravida pretium. Suspendisse ut dui eu ante cursus gravida non sed sem. Nullam sapien tellus, commodo id velit id, eleifend volutpat quam. Phasellus mauris velit, dapibus finibus elementum vel, pulvinar non tellus. Nunc pellentesque pretium diam, quis maximus dolor faucibus id. Nunc convallis sodales ante, ut ullamcorper est egestas vitae. Nam sit amet enim ultrices, ultrices elit pulvinar, volutpat risus.

output: 
  html_notebook: default
  rticles::plos_article: default
bibliography: cpas_covid_19.bib

# Some paper adjustments
---

2000/2500 words

# Introduction

The SARS-COV-2 global pandemic has exposed weaknesses throughout our institutions and organizations, and the social sciences is no exception. Even today, a half a year into the deadliest crisis most of us will ever see, we are still unable to answer basic questions about how human society should respond to the pandemic. [Example?]

As we consider the shape of things to come, we must also consider political science in the post COVID-19 age. To this conversation, we offer four lessons for social science from our own failures in understanding the pandemic.

<!-- Foremost, it showed that government institutions lack the capacity to  public health needs of their constituents.  -->

<!-- address all of the scientific, safety, and -->

<!-- Commercial, academic, and civil society efforts have stepped forward to fill this gap but often haltingly,  -->


# We must care about the truth

<!-- Let's face it, most of our audiences aren't interested in the truth. We must write to the few that do. And if that's not enough of an incentive to care about the truth, then as a field we must develop mechanisms to hold ourselves accountable.  -->


# Developing expertise is better than being an expert

<!-- You don't need to be an epidemiologist to make epidemiological claims, but you do need to use epidemiological models. Social scientists can (and should) drive in this lane, but there are some rules to the road -->


# Develop standing capabilities and collaborations



# Open source / publication process
<!-- Arhive getting hammered -->






# 1) We do not know how many people have had COVID-19 and we will likely never know.


# 2)  Measurements are constantly being aggregated and reaggreated by different actors, and aren't being archived systematically.

There is no one in charge, there are no adults in the room. 

Lit review of sources [@alamoCovid19OpenDataResources2020]

1Point3Acres [@yangCovidNetBringData2020]

New York Times [@albertsunNewYorkTimes2020]

Bing [@chiqunzhangBingCOVID19Data2020]

Yahoo [@ashleywolfYahooKnowledgeGraph2020]

USAfacts [@usafactsUSCoronavirusCases2020]

COVID Atlas li [@jzohrabCOVIDAtlasLi2020]

The Covid-Tracking Project [@zachliptonCovidTrackingProject2020]


# 3) The measurements we have don't agree with one another,

Sources don't agree with each other [@wangComparingIntegratingUS2020]


# 4) Desperately looking for other kinds of measurements but no real ground truth

Surveys

Early warning [@koganEarlyWarningApproach2020]

# 5) The sensors we use to estimate infections have their own complicated data generating processes which we also don't know and can't measure well.

Counts a basically proxing for testing availability not prevalence [@kaashoekCOVID19PositiveCases2020a]

Handling testing induced effects correctly [@kubinecRetrospectiveBayesianModel2020]

# 6) Contrarianism complicates science

# 7) Conformity complicates science
-Bad papers getting through
-Rough papers getting withdrawn
-General intolerance for uncertainty

# 8) Medical work with bad statistics

# 9) Social science with sophisticated statistics but no epidemiological model

# 10) Star hunting rather than explaining

# 11) Little evaluation, short memories, constantly changing models and forcasts.

Forecast Hub [@nicholasgreichReichlabCovid19forecasthubPrepublication2020]

Don't be discouraged but do the reading.
Bayesian estimate of R_t @[#BayesianNowcastingAdjustment]




Government responses "13,000 such policy announcements across more than 195 countries" [@chengCOVID19GovernmentResponse2020]








Dirty secrets - private institutions produce the data, government institutions aggregate it, private institutions aggregate it again.

We're almost always looking under the streetlamp.

We don't have mechanisms for sorting good evidence from bad.


New York Times partnered with Kaiser
Facts on File
CDC Flu View
serelogical evidene

Data science transforms information from one form into another, e.g. county PDFs into time series databases.

Data science studies the institutional data generating processes, reporting varies, that variation can and often is bigger than the signal empiricists want to test in their models.

Data science concerned with performance, and evaluation, e.g. forcasting and measuring performance.


The dirty secret of COVID-19 modeling is that there just isn't that much unique information there. You can torture a panel dataset with a small number of units and a high auto-correlation between time units into telling you whatever you want, but that doesn't make it true.


### Model evaluation and forcasting


Don't be discouraged but do the reading.

# References
